=== Stage 1: Zielgeschwindigkeit 0.1 m/s ===
Actor MLP: Sequential(
  (0): Linear(in_features=33, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=8, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=33, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
[DEBUG] Observation (env 0): tensor([-0.0033,  0.0266, -0.2061,  0.0104,  0.0103,  0.0169, -0.0005,  0.0005,
        -0.0005, -0.0005, -0.0005,  0.0006, -0.0005, -0.0005, -0.0034,  0.0034,
        -0.0032, -0.0032, -0.0034,  0.0037, -0.0035, -0.0035,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1000,  0.0000,
         0.0000], device='cuda:0')
[DEBUG] Action      (env 0): tensor([-0.2889,  1.6923, -0.2446, -0.2126, -0.0399,  0.8113, -0.4334, -0.3911],
       device='cuda:0')
[DEBUG] Reward      (env 0): tensor(0.0279, device='cuda:0')
[WandB] Iter 0 | reward=0.02 | loss=0.0115
[WandB] Iter 0 | reward=0.02 | loss=0.0115
[Plot] saved to logs/dodo-walking/metrics.png
[WandB] Iter 1 | reward=0.02 | loss=0.0450
[WandB] Iter 1 | reward=0.02 | loss=0.0450
[WandB] Iter 2 | reward=0.02 | loss=0.0146
[WandB] Iter 2 | reward=0.02 | loss=0.0146
[WandB] Iter 3 | reward=0.02 | loss=0.0094
[WandB] Iter 3 | reward=0.02 | loss=0.0094
[WandB] Iter 4 | reward=0.02 | loss=0.0087
[WandB] Iter 4 | reward=0.02 | loss=0.0087
[WandB] Iter 5 | reward=0.02 | loss=0.0056
[WandB] Iter 5 | reward=0.02 | loss=0.0056
[WandB] Iter 6 | reward=0.02 | loss=0.0030
[WandB] Iter 6 | reward=0.02 | loss=0.0030
[WandB] Iter 7 | reward=0.02 | loss=0.0017
[WandB] Iter 7 | reward=0.02 | loss=0.0017
[WandB] Iter 8 | reward=0.02 | loss=0.0011
[WandB] Iter 8 | reward=0.02 | loss=0.0011
[WandB] Iter 9 | reward=0.02 | loss=0.0007
[WandB] Iter 9 | reward=0.02 | loss=0.0007
Traceback (most recent call last):
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_train.py", line 324, in <module>
    main()
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_train.py", line 309, in main
    runner.learn(
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_train.py", line 248, in learn
    obs, rewards, dones, infos = self.env.step(actions.to(self.env.device))
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_env.py", line 243, in step
    self.reset_idx(done_ids)
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_env.py", line 163, in reset_idx
    self.scene.reset(env_ids)
  File "/home/hoan/Genesis/genesis/utils/misc.py", line 101, in wrapper
    return method(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/Genesis/genesis/engine/scene.py", line 677, in reset
    self._reset(state, envs_idx)
  File "/home/hoan/Genesis/genesis/engine/scene.py", line 685, in _reset
    self._sim.reset(state, envs_idx)
  File "/home/hoan/Genesis/genesis/engine/simulator.py", line 207, in reset
    solver.set_state(0, solver_state, envs_idx)
  File "/home/hoan/Genesis/genesis/engine/solvers/tool_solver.py", line 68, in set_state
    assert len(state) == len(self._entities)
           ^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/_tensor.py", line 1161, in __len__
    return handle_torch_function(Tensor.__len__, (self,), self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/overrides.py", line 1721, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/_tensor.py", line 1163, in __len__
    raise TypeError("len() of a 0-d tensor")
TypeError: len() of a 0-d tensor
Traceback (most recent call last):
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_train.py", line 324, in <module>
    main()
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_train.py", line 309, in main
    runner.learn(
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_train.py", line 248, in learn
    obs, rewards, dones, infos = self.env.step(actions.to(self.env.device))
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_env.py", line 243, in step
    self.reset_idx(done_ids)
  File "/home/hoan/Desktop/Malte/MalteVSC/dodo_Genesis_RL/dodo_env.py", line 163, in reset_idx
    self.scene.reset(env_ids)
  File "/home/hoan/Genesis/genesis/utils/misc.py", line 101, in wrapper
    return method(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/Genesis/genesis/engine/scene.py", line 677, in reset
    self._reset(state, envs_idx)
  File "/home/hoan/Genesis/genesis/engine/scene.py", line 685, in _reset
    self._sim.reset(state, envs_idx)
  File "/home/hoan/Genesis/genesis/engine/simulator.py", line 207, in reset
    solver.set_state(0, solver_state, envs_idx)
  File "/home/hoan/Genesis/genesis/engine/solvers/tool_solver.py", line 68, in set_state
    assert len(state) == len(self._entities)
           ^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/_tensor.py", line 1161, in __len__
    return handle_torch_function(Tensor.__len__, (self,), self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/overrides.py", line 1721, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hoan/miniconda3/envs/dodolab/lib/python3.12/site-packages/torch/_tensor.py", line 1163, in __len__
    raise TypeError("len() of a 0-d tensor")
TypeError: len() of a 0-d tensor

[38;5;9m[Genesis] [16:02:27] [ERROR] TypeError: len() of a 0-d tensor[0m
